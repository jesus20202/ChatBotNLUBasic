Plan Detallado para Integrar spaCy en DataBot Chat IA
üéØ Objetivo General
Modernizar el sistema NLU (Natural Language Understanding) del chatbot reemplazando la dependencia del LLM con un sistema h√≠brido basado en spaCy para clasificaci√≥n de intenciones y extracci√≥n de entidades.
üìã Fase 1: Preparaci√≥n del Entorno
1.1 Instalaci√≥n de Dependencias
bash# Instalar spaCy y modelo en espa√±ol
pip install spacy
python -m spacy download es_dep_news_trf

# Verificar instalaci√≥n
python -c "import spacy; nlp = spacy.load('es_dep_news_trf'); print('‚úÖ Modelo cargado correctamente')"
1.2 Restructuraci√≥n del Directorio NLU
Crear la nueva estructura de carpetas:
nlu/
‚îú‚îÄ‚îÄ spacy_model/
‚îÇ   ‚îî‚îÄ‚îÄ modelo_intenciones/    # Modelo entrenado (se generar√° despu√©s)
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ train_intent_classifier.py
‚îÇ   ‚îî‚îÄ‚îÄ training_data.json     # Datos de entrenamiento
‚îú‚îÄ‚îÄ spacy_intent_classifier.py
‚îú‚îÄ‚îÄ spacy_entity_extractor.py
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ config.py                 # Configuraciones del NLU
üìã Fase 2: Preparaci√≥n de Datos de Entrenamiento
2.1 Crear Datos de Entrenamiento (training_data.json)
json{
  "intents": {
    "buscar_producto": [
      "Quiero buscar laptops",
      "Mu√©strame celulares Samsung",
      "Necesito encontrar aud√≠fonos",
      "Busco productos de tecnolog√≠a",
      "¬øTienen tablets disponibles?"
    ],
    "comparar_precios": [
      "Compara precios de iPhone",
      "¬øCu√°l es m√°s barato?",
      "Muestra diferencias de precio",
      "Quiero comparar estos productos",
      "¬øQu√© opci√≥n es m√°s econ√≥mica?"
    ],
    "recomendar_categoria": [
      "Recomi√©ndame algo bueno",
      "¬øQu√© producto me sugieres?",
      "Dame una recomendaci√≥n",
      "¬øCu√°l es el mejor de esta categor√≠a?",
      "Ay√∫dame a elegir"
    ]
  }
}
2.2 Configuraci√≥n del Sistema (config.py)
python# Configuraciones del NLU
INTENT_THRESHOLD = 0.7  # Umbral m√≠nimo de confianza
ENTITY_LABELS = {
    "PRODUCT": "categoria",
    "ORG": "marca", 
    "MONEY": "rango_precio",
    "PERSON": "usuario"
}
MODEL_PATH = "nlu/spacy_model/modelo_intenciones"
üìã Fase 3: Desarrollo del Sistema de Entrenamiento
3.1 Script de Entrenamiento (train_intent_classifier.py)
Prompt para Copilot:
python# Estoy desarrollando un chatbot NLU en espa√±ol.
# Necesito un script que use spaCy para entrenar un clasificador de intenciones (textcat).
# El modelo base debe ser "es_dep_news_trf".
# Las intenciones son: "buscar_producto", "comparar_precios", "recomendar_categoria".
# Cargar datos desde training_data.json
# El resultado debe ser guardado en `nlu/spacy_model/modelo_intenciones/`.
# Usar entrenamiento con Example.from_dict y mostrar progreso.
# Incluir validaci√≥n cruzada simple.
3.2 Estructura del Script de Entrenamiento
pythonimport spacy
import json
import random
from spacy.training import Example
from spacy.util import minibatch, compounding

class IntentTrainer:
    def __init__(self):
        self.nlp = spacy.load("es_dep_news_trf")
        self.training_data = self.load_training_data()
        
    def load_training_data(self):
        # Cargar desde training_data.json
        pass
        
    def prepare_examples(self):
        # Convertir datos a formato spaCy
        pass
        
    def train_model(self, iterations=20):
        # Entrenar modelo con textcat
        pass
        
    def save_model(self):
        # Guardar modelo entrenado
        pass
üìã Fase 4: Desarrollo del Clasificador de Intenciones
4.1 Clasificador ML (spacy_intent_classifier.py)
Prompt para Copilot:
python# Crear una clase MLIntentClassifier que cargue el modelo spaCy entrenado de `nlu/spacy_model/modelo_intenciones`.
# Debe tener un m√©todo `classify(text)` que devuelva la intenci√≥n y confianza.
# Incluir manejo de errores si el modelo no existe.
# Agregar m√©todo para obtener todas las probabilidades de intenciones.
# Usar umbral de confianza configurable.
4.2 Estructura del Clasificador
pythonclass MLIntentClassifier:
    def __init__(self, model_path="nlu/spacy_model/modelo_intenciones"):
        self.nlp = None
        self.model_path = model_path
        self.load_model()
        
    def load_model(self):
        # Cargar modelo con manejo de errores
        pass
        
    def classify(self, text: str) -> tuple:
        # Clasificar intenci√≥n principal
        pass
        
    def get_all_probabilities(self, text: str) -> dict:
        # Obtener todas las probabilidades
        pass
üìã Fase 5: Desarrollo del Extractor de Entidades
5.1 Extractor de Entidades (spacy_entity_extractor.py)
Prompt para Copilot:
python# Crear una clase EntityExtractor que use spaCy es_dep_news_trf para extraer entidades.
# Las entidades de inter√©s son: PRODUCT, ORG, MONEY, PERSON.
# Mapear esas entidades a: "categoria", "marca", "rango_precio", "usuario".
# Usar post-procesamiento para limpiar y normalizar entidades.
# Incluir m√©todo para extraer entidades personalizadas usando patrones.
# Agregar filtros para entidades irrelevantes.
5.2 Estructura del Extractor
pythonclass EntityExtractor:
    def __init__(self):
        self.nlp = spacy.load("es_dep_news_trf")
        self.entity_mapping = ENTITY_LABELS
        
    def extract(self, text: str) -> dict:
        # Extraer entidades principales
        pass
        
    def extract_custom_entities(self, text: str) -> dict:
        # Extraer entidades personalizadas con patrones
        pass
        
    def post_process_entities(self, entities: dict) -> dict:
        # Limpiar y normalizar entidades
        pass
üìã Fase 6: Integraci√≥n del Sistema NLU
6.1 Procesador Principal (nlu/init.py)
Prompt para Copilot:
python# Crear una clase NLUProcessor que combine:
# - spacy_intent_classifier.MLIntentClassifier para intenciones
# - spacy_entity_extractor.EntityExtractor para entidades
# M√©todo: process(text: str) -> dict con keys: intent, confidence, entities
# Incluir fallback si la confianza es baja
# Agregar logging para debugging
# Manejar errores graciosamente
6.2 Estructura del Procesador
pythonclass NLUProcessor:
    def __init__(self):
        self.intent_classifier = MLIntentClassifier()
        self.entity_extractor = EntityExtractor()
        self.logger = self.setup_logger()
        
    def process(self, text: str) -> dict:
        # Procesar texto completo
        pass
        
    def fallback_processing(self, text: str) -> dict:
        # Procesamiento alternativo si falla ML
        pass
üìã Fase 7: Actualizaci√≥n de la Aplicaci√≥n Principal
7.1 Modificar main.py o app.py
python# Reemplazar el NLU actual con el nuevo
from nlu import NLUProcessor

# Inicializar una sola vez
nlu_processor = NLUProcessor()

@app.route('/chat', methods=['POST'])
def chat():
    message = request.json.get('message')
    
    # Usar nuevo NLU
    nlu_result = nlu_processor.process(message)
    
    # Procesar resultado
    if nlu_result['confidence'] > 0.7:
        # Usar resultado ML
        response = handle_intent(nlu_result)
    else:
        # Fallback al LLM si es necesario
        response = fallback_llm_processing(message)
    
    return jsonify(response)
üìã Fase 8: Testing y Validaci√≥n
8.1 Script de Pruebas (test_nlu.py)
pythondef test_intent_classification():
    # Probar clasificaci√≥n de intenciones
    test_cases = [
        ("Busco laptops baratas", "buscar_producto"),
        ("Compara precios de celulares", "comparar_precios"),
        ("Recomi√©ndame algo bueno", "recomendar_categoria")
    ]
    
def test_entity_extraction():
    # Probar extracci√≥n de entidades
    test_cases = [
        ("Busco laptops Lenovo baratas", {"categoria": "laptops", "marca": "Lenovo"}),
        ("iPhone 15 de $800", {"categoria": "iPhone", "rango_precio": "$800"})
    ]
    
def test_full_pipeline():
    # Probar pipeline completo
    pass
8.2 M√©tricas de Evaluaci√≥n

Precisi√≥n de clasificaci√≥n de intenciones
Recall de extracci√≥n de entidades
Tiempo de respuesta
Uso de memoria

üìã Fase 9: Optimizaci√≥n y Monitoreo
9.1 Logging y Monitoreo
pythonimport logging

def setup_nlu_logger():
    logger = logging.getLogger('nlu')
    logger.setLevel(logging.INFO)
    handler = logging.FileHandler('nlu_performance.log')
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    return logger
9.2 M√©tricas de Performance

Tiempo de procesamiento por mensaje
Confianza promedio de clasificaciones
Entidades extra√≠das por mensaje
Casos de fallback al LLM

üìã Fase 10: Despliegue y Mantenimiento
10.1 Checklist de Despliegue

 Modelo entrenado y guardado
 Todos los tests pasando
 Logging configurado
 Documentaci√≥n actualizada
 Backup del sistema anterior

10.2 Plan de Mantenimiento

Semanal: Revisar logs de performance
Mensual: Evaluar precisi√≥n del modelo
Trimestral: Reentrenar modelo con nuevos datos
Seg√∫n necesidad: Agregar nuevas intenciones

üéØ Resultados Esperados
Beneficios Inmediatos:

Reducci√≥n del 70% en el uso de tokens LLM
Tiempo de respuesta 3x m√°s r√°pido
Mayor consistencia en clasificaci√≥n
Mejor extracci√≥n de entidades en espa√±ol

M√©tricas de √âxito:

Precisi√≥n de intenciones > 85%
Tiempo de respuesta < 200ms
Reducci√≥n de costos LLM > 60%
Satisfacci√≥n del usuario mantenida

Este plan te permitir√° integrar spaCy de manera sistem√°tica y eficiente, manteniendo la calidad del chatbot mientras reduces costos y mejoras el rendimiento.